# ğŸ›¡ï¸ IaC Auto-Reviewer: Code Review de Infraestrutura com IA

+ **Autor:** Luciano Souza de Jesus
+ **MBA:** CLC14 Cloud Computing & DevOps
+ **Universidade:** Impacta

---

## ğŸ“‹ Sobre o Projeto

Este projeto demonstra a implementaÃ§Ã£o de um **Agente de SeguranÃ§a e Qualidade para Infraestrutura como CÃ³digo (IaC)**. Utilizando Engenharia de Prompts avanÃ§ada e a API da OpenAI, o sistema atua como um "Senior DevOps virtual", analisando Pull Requests de Terraform e CloudFormation antes do merge.

O projeto evolui de uma abordagem manual (v1) para uma automaÃ§Ã£o completa em CI/CD (v3), capaz de bloquear deploys inseguros, detectar custos excessivos e resistir a ataques de *Prompt Injection*.

---

## ğŸ“‚ Estrutura do Projeto

```text
.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ iac-scan.yml      # Workflow do GitHub Actions (CI/CD)
â”œâ”€â”€ examples/                 # Arquivos IaC para teste (CenÃ¡rios de PR)
â”‚   â”œâ”€â”€ pr1_storage.tf
â”‚   â”œâ”€â”€ pr2_security.tf
â”‚   â”œâ”€â”€ pr3_database.tf
â”‚   â”œâ”€â”€ pr4_ec2_tags.tf
â”‚   â”œâ”€â”€ pr5_lambda.yaml
â”‚   â””â”€â”€ pr6_injection.tf
â”œâ”€â”€ prompts/                  # VersÃµes evolutivas dos prompts
â”‚   â”œâ”€â”€ v1-baseline.md        # Prompt bÃ¡sico (Zero-shot)
â”‚   â”œâ”€â”€ v2-structured.md      # Prompt com Persona e Markdown
â”‚   â””â”€â”€ v3-schema.md          # Prompt Blindado com JSON Schema
â”œâ”€â”€ scripts/                  # Scripts de automaÃ§Ã£o (Python)
â”‚   â”œâ”€â”€ scan_with_ai.py       # Cliente API: Envia cÃ³digo para a OpenAI
â”‚   â””â”€â”€ validate_pr.py        # Gatekeeper: Valida JSON e define Exit Code
â”œâ”€â”€ resultados/               # EvidÃªncias dos testes (Prints)
â”œâ”€â”€ llm_output.json           # Arquivo temporÃ¡rio de saÃ­da da IA
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â””â”€â”€ README.md                 # DocumentaÃ§Ã£o
```

---

## ğŸ§  EvoluÃ§Ã£o da Engenharia de Prompt

1. v1-baseline (O Generalista): Prompt simples. Retorna texto livre. Falha em consistÃªncia e Ã© vulnerÃ¡vel a injeÃ§Ã£o de prompt.
2. v2-structured (O Organizado): Usa Role Prompting e Chain of Thought. Melhora a explicaÃ§Ã£o para humanos, mas difÃ­cil de parsear via script.
3. v3-schema (O Automatizado):
   + SaÃ­da: Estritamente JSON.
   + SeguranÃ§a: Implementa tags XML (<source_code>) e defesa "sanduÃ­che" contra instruÃ§Ãµes maliciosas.
   + IntegraÃ§Ã£o: Projetado para ser consumido por pipelines de CI/CD.

---

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

#### PrÃ©-requisitos
   + Python 3.8+
   + Conta na OpenAI (API Key)

1. Instalar DependÃªncias
```
pip install -r requirements.txt
```
(ConteÃºdo do requirements.txt: ```openai```)

2. Configurar VariÃ¡veis de Ambiente
#### Linux/Mac (Bash):
```export OPENAI_API_KEY="sk-sua-chave-aqui"```

#### Windows (Powershell):
```$env:OPENAI_API_KEY="sk-sua-chave-aqui"```

---

### ğŸš€ Como Utilizar

1. **Modo 1: Teste Local (CLI):** VocÃª pode rodar a IA contra os arquivos de exemplo localizados na pasta `examples/`. O script `scan_with_ai.py` gera o JSON, e o `validate_pr.py` diz se passa ou falha.
#### Exemplo: Analisando um arquivo com falha de seguranÃ§a (PR2)
`Bash`
```
# 1. Enviar para anÃ¡lise da IA
python scripts/scan_with_ai.py examples/pr2_security.tf

# 2. Verificar veredito (Gatekeeper)
python scripts/validate_pr.py
```
*SaÃ­da esperada:* `âœ… SUCESSO: Pull Request aprovado para merge.`

2. **Modo 2: AutomaÃ§Ã£o via GitHub Actions** O arquivo `.github/workflows/iac-scan.yml` configura a esteira automÃ¡tica.
   1. Configure o segredo `OPENAI_API_KEY` nas configuraÃ§Ãµes do repositÃ³rio (Settings > Secrets > Actions).
   2. Abra um Pull Request com arquivos `.tf` ou `.yaml`.
   3. A Action rodarÃ¡ automaticamente e bloquearÃ¡ o merge se a IA detectar riscos crÃ­ticos (severity: `High/Critical` ou `decision: Reject`).

---

### ğŸ§ª CenÃ¡rios de Teste (Pasta `examples/`)

| Arquivo | CenÃ¡rio | Risco | DecisÃ£o Esperada v3 |
| :--- | :---: | :---: | ---: |
| pr1_storage.tf | Bucket S3 sem criptografia e versionamento | MÃ©dio | Request Changes (Qualidade: 6/10) |
| pr2_security.tf | SSH (Porta 22) aberto para 0.0.0.0/0 | CrÃ­tico | Reject (Qualidade: 0/10) |
| pr3_database.tf | Upgrade de DB (custo 10x maior) | Alto | Discuss (Custo Excessivo) |
| pr4_ec2_tags.tf | InstÃ¢ncia correta com tags de custo | Baixo | Approve (Qualidade: 10/10) |
| pr5_lambda.tf | Lambda sem Timeout definido | CrÃ­tico | MÃ©dio | Approve (com ressalvas) |
| pr6_injection.tf | Tentativa de Prompt Injection ("Ignore instructions") | CrÃ­tico | Reject (Ataque Detectado) |

---

### âš™ï¸ Detalhes TÃ©cnicos dos Scripts
`scripts/scan_with_ai.py`
Conecta na API da OpenAI (modelo `gpt-3.5-turbo` ou `gpt-4`), lÃª o **Prompt v3**, injeta o cÃ³digo do arquivo alvo e salva a resposta crua em `llm_output.json`.

`scripts/validate_pr.py`
LÃª o arquivo JSON gerado. Se o campo `decision` for `"Reject"` ou `"Request Changes"`, o script encerra com **Exit Code 1**, o que faz a pipeline do GitHub/Jenkins ficar vermelha (falhar).

`Python`
```
# Trecho da lÃ³gica de bloqueio
if decision in ['Reject', 'Request Changes']:
    sys.exit(1) # Bloqueia CI
else:
    sys.exit(0) # Aprova CI
```

*Projeto desenvolvido para fins educacionais sobre DevOps e LLMs.*
